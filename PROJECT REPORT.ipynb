{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b422fe7",
   "metadata": {},
   "source": [
    "**Báo cáo cuối kỳ môn học: PYTHON CHO KHOA HỌC DỮ LIỆU**\n",
    "\n",
    "**Lớp 23TTH, Khoa Toán - Tin học, Trường Đại học Khoa học Tự nhiên, ĐHQG-HCM**\n",
    "\n",
    "**Đề tài thực hiện:**\n",
    "$$\n",
    "\\text{\\textbf{USING DEEP LEARNING TO CLASSIFY ANIMAL AND HUMAN IMAGES}}\n",
    "$$\n",
    "\n",
    "**Giảng viên hướng dẫn: ThS. Hà Văn Thảo**\n",
    "\n",
    "**Danh sách thành viên nhóm:**\n",
    "\n",
    "1. 23110114 - Nguyễn Thị Hồng Thắm \\\n",
    "2. 23110123 - Lê Huỳnh Yến Vy \\\n",
    "3. 23110132 - Trần Nhật Anh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec77e2",
   "metadata": {},
   "source": [
    "## GIỚI THIỆU\n",
    "\n",
    "Object detection là một trong những chủ đề \"nóng\" trong deep learing bởi tính ứng dụng cao trong thực tiễn và nguồn dữ liệu dồi dào, dễ chuẩn bị. Một trong những thuật toán object detection nổi tiếng nhất là **YOLO**.\n",
    "\n",
    "YOLO là mô hình mạng neuron tích chập (CNN) được sử dụng phổ biển để nhận dạng các đối tượng trong ảnh hoặc video. Điểm đặc biệt của mô hình này là có khả năng phát hiện tất cả các đối tượng trong một hình ảnh chỉ qua một lần lan truyền của CNN.\n",
    "\n",
    "Các phương pháp truyền thống tách biệt bước đề xuất vùng và bước phân loại, YOLO xử lý đầu vào, vừa phân loại được các đối tượng, vừa dự đoán được vị trí của chúng trong một lần duy nhất.\n",
    "\n",
    "YOLO có nghĩa là \"You only look once\", nghĩa là chỉ cần \"nhìn\" một lần là thuật toán đã có thể phát hiện được vật thể, cho thấy độ nhanh của thuật toán gần như là real-time.\n",
    "\n",
    "Ứng dụng của YOLO cũng như nhiều thuật toán object detection khác, rất đa dạng: quản lý giao thông, đếm số sản phẩm trên băng chuyền nhà máy, đếm số vật nuôi trong chăn nuôi, phát hiện vật thể nguy hiểm (súng, dao,...), chấm công tự động,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c9885",
   "metadata": {},
   "source": [
    "## TẠO MÔI TRƯỜNG ẢO VÀ KERNEL CHẠY NOTEBOOK (LINUX)\n",
    "\n",
    "Dự án Python cần **môi trường ảo (virtual environment)** để tự cách ly, tránh xung đột phiên bản thư viện giữa các dự án. `venv` là môi trường ảo mà chúng ta sẽ sử dụng trong dự án này. Sau khi cài đặt `venv`, chúng ta di chuyển đường dẫn đến folder chứa dự án trong terminal và sử dụng lệnh sau để cài đặt môi trường ảo cho dự án:\n",
    "\n",
    "`python -m venv .venv`\n",
    "\n",
    "Trong đó, `.venv` là tên của folder chứa môi trường ảo của dự án, đồng thời nó cũng sẽ \"đóng băng\" phiên bản Python, pip và các thư viện sẽ được dùng trong dự án.\n",
    "\n",
    "Kích hoạt môi trường ảo:\n",
    "\n",
    "`source .venv/bin/activate`\n",
    "\n",
    "Lúc này, phiên bản Python và `pip` được dùng là của môi trường ảo, các thư viện cài bằng `pip install` cũng chỉ ảnh hưởng trong `.venv`. Cách nhận biết đang ở môi trường ảo là promt terminal thường đổi thành `(.venv) user_name@machine:~` (nếu đang sử dụng Linux). Khi đã kích hoạt môi trường ảo, đảm bảo phiên bản Python và `pip` đã \"đóng băng\" trong đó, sử dụng lệnh:\n",
    "\n",
    "`which python && which pip`\n",
    "\n",
    "Nếu output có dạng `.../<project_name>/.venv/...` thì môi trường ảo đã được kích hoạt thành công.\n",
    "\n",
    "Tiếp theo, tạo một kernel để chạy Jupyter Notebook. Cài đặt `ipykernel` để tạo kernel:\n",
    "\n",
    "`python -m pip install ipykernel`\n",
    "\n",
    "Sau khi cài đặt thành công, tiến hành tạo kernel để chạy file `.ipynb`:\n",
    "\n",
    "`python -m ipykernel install --prefix .venv --name yolovenv --display-name \"this_project\"`\n",
    "\n",
    "`--prefix .venv`: kernel mặc định không tự lưu vào `.venv`, thuộc tính này sẽ lưu kernel đã tạo vào `.venv`  \n",
    "`--name yolovenv`: tên folder chứa kernel, ở đây tên folder là `yolovenv`. Kernel sẽ được lưu tại `.venv/share/jupyter/kernels/yolovenv/`  \n",
    "`--display-name \"this_project`: kernel sẽ hiển thị dưới tên `this_project` trong VS Code.\n",
    "\n",
    "Khi đã tạo kernel, click vào biểu tượng kernel ở góc trên bên phải, chọn\n",
    "$$\n",
    "\\text{Select Another Kernel} \\rightarrow \\text{Jupyter Kernel...} \\rightarrow \\text{this\\_project}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f1757",
   "metadata": {},
   "source": [
    "# CÁC THƯ VIỆN CẦN DÙNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513c7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de95248",
   "metadata": {},
   "source": [
    "# CHUẨN BỊ DỮ LIỆU VÀ TỔNG QUAN VỀ DỮ LIỆU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c99e5",
   "metadata": {},
   "source": [
    "Dữ liệu được tải về tại các nguồn sau: \\\n",
    "- https://www.kaggle.com/datasets/antoreepjana/animals-detection-images-dataset \\\n",
    "- https://www.kaggle.com/datasets/biancaferreira/african-wildlife \\\n",
    "- https://www.kaggle.com/datasets/wutheringwang/dog-face-detectionyolo-format \\\n",
    "- https://www.kaggle.com/datasets/samuelayman/cat-dataset\\\n",
    "- https://universe.roboflow.com/labo-yolo/age-and-gender-xlnfj/dataset/3\n",
    "\n",
    "Dữ liệu sau khi được tải về sẽ được xử lý (gán lại class ID; phân loại thành các folder train, valid, test;...), sau đó được gộp thành một folder tập dữ liệu (dataset) duy nhất. Dataset nếu muốn được YOLO \"hiểu\" thì phải có file `.yaml` chứa các thông tin về dataset như vị trí của file train, valid, test; số class; tên của các class ứng với mỗi class_id;...\n",
    "\n",
    "Dataset của dự án này nằm tại `dataset/complete_dataset`, bao gồm: \\\n",
    "- folder `images` chứa các file ảnh, được chia thành ba folder train, valid, test \\\n",
    "- folder `labels` chứa các file **nhãn dữ liệu (label)** có đuôi `.txt`, cũng được chia thành ba folder train, valid, test và các file label có tên ứng với các file ảnh\n",
    "- file `.yaml` để cung cấp thông tin về dataset cho YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3836e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset/complete_dataset/data.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c076f8",
   "metadata": {},
   "source": [
    "Trước khi đưa dataset vào huấn luyện mô hình, cần làm sạch và chuẩn hoá dataset để tránh các lỗi crash, lỗi đọc ảnh,... trong quá trình huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55b460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_flag_file(BASE_DIR):\n",
    "    flag_file = BASE_DIR / \"flag_file.txt\"\n",
    "\n",
    "    if not flag_file.exists():\n",
    "        return False\n",
    "    \n",
    "    with open(flag_file, 'r') as file:\n",
    "        return file.read().strip() == \"This dataset has been re-saved already.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca46d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flag_file(BASE_DIR):\n",
    "    if check_flag_file(BASE_DIR):\n",
    "        return\n",
    "    \n",
    "    flag_file = BASE_DIR / \"flag_file.txt\"\n",
    "    content = \"This dataset has been re-saved already.\"\n",
    "\n",
    "    with open(flag_file, 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8d363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resave(IMAGES_DIR, LABELS_DIR):\n",
    "    fixed = 0\n",
    "    removed = 0\n",
    "\n",
    "    for root, _, files in os.walk(IMAGES_DIR):\n",
    "        for file in files:\n",
    "            if not file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".webp\")):\n",
    "                continue\n",
    "\n",
    "            # Ghép IMAGES_DIR với tên file ảnh thành path file ảnh\n",
    "            image_path = os.path.join(root, file)\n",
    "\n",
    "            try:\n",
    "                # Mở ảnh để verify nhanh, nếu ảnh có vấn đề -> exception\n",
    "                with Image.open(image_path) as image:\n",
    "                    image.verify()\n",
    "\n",
    "                # Mở lại để re-save\n",
    "                with Image.open(image_path) as image:\n",
    "                    image = image.convert(\"RGB\")\n",
    "                    image.save(image_path, \"JPEG\", quality=95, subsampling=0)\n",
    "\n",
    "                fixed += 1\n",
    "\n",
    "            except Exception:\n",
    "                # Nếu ảnh hỏng -> xoá file ảnh cùng với file label tương ứng\n",
    "                os.remove(image_path)\n",
    "                removed += 1\n",
    "\n",
    "                relative_path = os.path.relpath(root, IMAGES_DIR)\n",
    "\n",
    "                label_path = os.path.join(\n",
    "                    LABELS_DIR,\n",
    "                    relative_path,\n",
    "                    os.path.splitext(file)[0] + \".txt\"\n",
    "                )\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    os.remove(label_path)\n",
    "\n",
    "    return fixed, removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba0f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resave_images(BASE_DIR, IMAGES_DIR, LABELS_DIR):\n",
    "    if check_flag_file(BASE_DIR):\n",
    "        return 0, 0\n",
    "    else:\n",
    "        fixed, removed = resave(IMAGES_DIR, LABELS_DIR)\n",
    "        create_flag_file(BASE_DIR)\n",
    "\n",
    "        return fixed, removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7dcef7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed  : 0\n",
      "Removed: 0\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(\"dataset/complete_dataset\")\n",
    "IMAGES_DIR = \"dataset/complete_dataset/images\"\n",
    "LABELS_DIR = \"dataset/complete_dataset/labels\"\n",
    "\n",
    "fixed, removed = resave_images(BASE_DIR, IMAGES_DIR, LABELS_DIR)\n",
    "\n",
    "print(\"Fixed  :\", fixed)\n",
    "print(\"Removed:\", removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d910097",
   "metadata": {},
   "source": [
    "Sau khi hoàn tất xử lý dataset, dùng hàm `count_missing` để kiểm tra xem với mỗi file ảnh thì có file label tương ứng hay không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b96bf0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing(BASE_DIR, image_exts, sub_folder):\n",
    "    images_dir = BASE_DIR / \"images\" / sub_folder\n",
    "    labels_dir = BASE_DIR / \"labels\" / sub_folder\n",
    "\n",
    "    images_cnt = 0\n",
    "    missing_cnt = 0\n",
    "\n",
    "    for image in images_dir.iterdir():\n",
    "        if image.suffix.lower() not in image_exts:\n",
    "            continue\n",
    "\n",
    "        images_cnt += 1\n",
    "        \"\"\"\n",
    "        image.stem dùng để lấy tên của file image mà không có phần mở rộng\n",
    "        Ví dụ: example123.png -> example123\n",
    "        \"\"\"\n",
    "        label_file = labels_dir / f\"{image.stem}.txt\"\n",
    "        if not label_file.exists():\n",
    "            missing_cnt += 1\n",
    "\n",
    "    return images_cnt, missing_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a7335",
   "metadata": {},
   "source": [
    "Kiểm tra số ảnh bị thiếu label tương ứng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29e13ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset: dataset/complete_dataset\n",
      "\n",
      "       images  images/total (%)  missing_labels  missing_labels (%)\n",
      "train   20451         65.619585               0                 0.0\n",
      "valid    6078         19.502021               0                 0.0\n",
      "test     4637         14.878393               0                 0.0\n",
      "\n",
      "-> Total images:       31166\n",
      "-> Total missing:      0\n",
      "-> Total missing (%):  0.0\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(\"dataset/complete_dataset\")\n",
    "image_exts = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
    "sub_folders = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "print(f\"Checking dataset: {str(BASE_DIR)}\\n\")\n",
    "\n",
    "total_images = 0\n",
    "total_missing = 0\n",
    "images_cnt_arr = np.array([])\n",
    "missing_cnt_arr = np.array([])\n",
    "missing_percent_arr = np.array([])\n",
    "\n",
    "for sub_folder in sub_folders:\n",
    "    images_cnt, missing_cnt = count_missing(BASE_DIR, image_exts, sub_folder)\n",
    "    total_images += images_cnt\n",
    "    total_missing += missing_cnt\n",
    "\n",
    "    missing_percent = (missing_cnt / images_cnt) * 100 if images_cnt > 0 else 0\n",
    "\n",
    "    images_cnt_arr = np.append(images_cnt_arr, images_cnt)\n",
    "    missing_cnt_arr = np.append(missing_cnt_arr, missing_cnt)\n",
    "    missing_percent_arr = np.append(missing_percent_arr, missing_percent)\n",
    "\n",
    "images_percent = np.array([(images_cnt / total_images) * 100 \\\n",
    "                           for images_cnt in images_cnt_arr])\n",
    "\n",
    "np_table = np.array([images_cnt_arr, images_percent, \\\n",
    "                     missing_cnt_arr, missing_percent_arr])\n",
    "table = pd.DataFrame(np_table).transpose()\n",
    "table.columns = [\"images\", \"images/total (%)\", \"missing_labels\", \"missing_labels (%)\"]\n",
    "table.index = [\"train\", \"valid\", \"test\"]\n",
    "table['images'] = table['images'].astype(int)\n",
    "table['missing_labels'] = table['missing_labels'].astype(int)\n",
    "\n",
    "missing_percent = (total_missing / total_images) * 100 \\\n",
    "    if total_images > 0 else 0\n",
    "\n",
    "print(table)\n",
    "print(\"\")\n",
    "print(f\"-> Total images:       {total_images}\")\n",
    "print(f\"-> Total missing:      {total_missing}\")\n",
    "print(f\"-> Total missing (%):  {missing_percent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da97b8",
   "metadata": {},
   "source": [
    "Theo kết quả được in ra, dataset có tổng cộng 31166 ảnh và mỗi ảnh đều có file label tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54685499",
   "metadata": {},
   "source": [
    "# KHAI BÁO, HUẤN LUYỆN VÀ LƯU MÔ HÌNH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288825b",
   "metadata": {},
   "source": [
    "Phiên bản các thư viện dùng để huấn luyện mô hình: \\\n",
    "- Ultralytics 8.3.243 \\\n",
    "- Python-3.12.8 torch-2.9.1+cu128 CUDA:0 (NVIDIA RTX A6000, 48541MiB)\n",
    "\n",
    "Mô hình sẽ được huấn luyện với hai hàm `train_model` và `train_model_with_optimization`. Hàm `train_model_with_optimization` có thêm các tham số tối ưu hoá, huấn luyện mô hình để cho ra các kết quả dùng để so sánh ở các phần sau.\n",
    "\n",
    "Optimizer mặc định của YOLO11s/YOLO11m là `SGD`, mô hình sẽ được huấn luyện để so sánh với optimizer `AdamW`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25bea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, imgsz, dataset_path, project_path, project_name):\n",
    "    model.train(\n",
    "        exist_ok=True,\n",
    "        data=dataset_path,\n",
    "        project=project_path,\n",
    "        name=project_name,\n",
    "\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=32,\n",
    "        workers=12,\n",
    "        seed=42,\n",
    "        device=0,  # sử dụng GPU\n",
    "\n",
    "        cos_lr=True,\n",
    "\n",
    "        mosaic=0.1,\n",
    "        mixup=0.0,\n",
    "        copy_paste=0.0,\n",
    "\n",
    "        optimizer=\"SGD\",\n",
    "        lr0=0.01,\n",
    "        momentum=0.937,\n",
    "        weight_decay=5e-4,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_model_with_optimization(model, epochs, imgsz, dataset_path, \n",
    "                                  project_path, project_name):\n",
    "    model.train(\n",
    "        exist_ok=True,\n",
    "        data=dataset_path,\n",
    "        project=project_path,\n",
    "        name=project_name,\n",
    "\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=32,\n",
    "        workers=12,\n",
    "        seed=42,\n",
    "        device=0,  # sử dụng GPU\n",
    "\n",
    "        cos_lr=True,\n",
    "\n",
    "        mosaic=0.1,\n",
    "        mixup=0.0,\n",
    "        copy_paste=0.0,\n",
    "\n",
    "        optimizer=\"AdamW\",\n",
    "        lr0=0.001,\n",
    "        weight_decay=1e-2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc73cc",
   "metadata": {},
   "source": [
    "Sử dụng model YOLO11s và chuẩn bị các tham số để chuẩn bị train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1227b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODELS = [\"yolo11s\", \"yolo11m\"]\n",
    "\n",
    "epochs_list = [30, 80]\n",
    "imgsz_list = [448, 640]\n",
    "with_optimization_list = [0, 1]  # 0 = không optimization, 1 = có optimization\n",
    "\n",
    "# Huấn luyện mô hình với các thông số khác nhau\n",
    "parameters = list(product(epochs_list, imgsz_list, with_optimization_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4cb71",
   "metadata": {},
   "source": [
    "Huấn luyện mô hình với các tham số khác nhau dựa trên YOLO11s và YOLO11m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e345bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/yolo11s/epochs30_imgsz448_optimization0/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11s/epochs30_imgsz448_optimization1/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11s/epochs30_imgsz640_optimization0/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11s/epochs30_imgsz640_optimization1/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11s/epochs80_imgsz448_optimization0/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11s/epochs80_imgsz448_optimization1/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11s/epochs80_imgsz640_optimization0/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11s/epochs80_imgsz640_optimization1/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11m/epochs30_imgsz448_optimization0/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11m/epochs30_imgsz448_optimization1/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11m/epochs30_imgsz640_optimization0/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11m/epochs30_imgsz640_optimization1/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11m/epochs80_imgsz448_optimization0/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11m/epochs80_imgsz448_optimization1/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11m/epochs80_imgsz640_optimization0/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n",
      "runs/yolo11m/epochs80_imgsz640_optimization1/weights/best.pt\n",
      "Model has been trained already. It is being loaded again...\n"
     ]
    }
   ],
   "source": [
    "for base_model in BASE_MODELS:\n",
    "    for parameter in parameters:\n",
    "        epochs, imgsz, with_optimization = parameter\n",
    "\n",
    "        \"\"\"\n",
    "        Lưu model tại \"runs/{...}/epochs{...}_imgsz{...}_optimization{...}\"\n",
    "        sau khi train\n",
    "        \"\"\"\n",
    "        best_path = (\n",
    "            Path(f\"runs/{base_model}\")\n",
    "            / f\"epochs{epochs}_imgsz{imgsz}_optimization{with_optimization}\"\n",
    "            / \"weights\"\n",
    "            / \"best.pt\"\n",
    "        )\n",
    "        model_path = f\"runs/{base_model}\"\n",
    "        model_name = f\"epochs{epochs}_imgsz{imgsz}_optimization{with_optimization}\"\n",
    "\n",
    "        # Huấn luyện mô hình với dataset\n",
    "        if best_path.exists():\n",
    "            print(str(best_path))\n",
    "            print(f\"Model has been trained already. It is being loaded again...\")\n",
    "            model = YOLO(str(best_path))\n",
    "        else:\n",
    "            print(str(best_path))\n",
    "            print(\"Model hasn't been trained. Start training...\")\n",
    "\n",
    "            # Huấn luyện mô hình dựa trên mô hình gốc\n",
    "            model = YOLO(base_model)\n",
    "            if with_optimization:\n",
    "                train_model_with_optimization(\n",
    "                    model=model,\n",
    "                    epochs=epochs,\n",
    "                    imgsz=imgsz,\n",
    "                    dataset_path=DATASET_PATH,\n",
    "                    project_path=model_path,\n",
    "                    project_name=model_name\n",
    "                )\n",
    "            else:\n",
    "                train_model(\n",
    "                    model=model,\n",
    "                    epochs=epochs,\n",
    "                    imgsz=imgsz,\n",
    "                    dataset_path=DATASET_PATH,\n",
    "                    project_path=model_path,\n",
    "                    project_name=model_name\n",
    "                )\n",
    "\n",
    "            # Load lại best.pt sau khi train, nếu không tìm thấy thì in ra lỗi\n",
    "            assert best_path.exists(), \"Training finished but file best.pt not found\"\n",
    "            model = YOLO(str(best_path))\n",
    "\n",
    "            print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb95f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2eaa45e",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "this_project",
   "language": "python",
   "name": "yolovenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
