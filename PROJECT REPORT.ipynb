{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b422fe7",
   "metadata": {},
   "source": [
    "**Báo cáo cuối kỳ môn học: PYTHON CHO KHOA HỌC DỮ LIỆU**\n",
    "\n",
    "**Lớp 23TTH, Khoa Toán - Tin học, Trường Đại học Khoa học Tự nhiên, ĐHQG-HCM**\n",
    "\n",
    "**Đề tài thực hiện:**\n",
    "$$\n",
    "\\text{\\textbf{USING DEEP LEARNING TO CLASSIFY ANIMAL AND HUMAN IMAGES}}\n",
    "$$\n",
    "\n",
    "**Giảng viên hướng dẫn: ThS. Hà Văn Thảo**\n",
    "\n",
    "**Danh sách thành viên nhóm:**\n",
    "\n",
    "1. 23110114 - Nguyễn Thị Hồng Thắm \\\n",
    "2. 23110123 - Lê Huỳnh Yến Vy \\\n",
    "3. 23110132 - Trần Nhật Anh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec77e2",
   "metadata": {},
   "source": [
    "## GIỚI THIỆU\n",
    "\n",
    "Object detection là một trong những chủ đề \"nóng\" trong deep learing bởi tính ứng dụng cao trong thực tiễn và nguồn dữ liệu dồi dào, dễ chuẩn bị. Một trong những thuật toán object detection nổi tiếng nhất là **YOLO**.\n",
    "\n",
    "YOLO là mô hình mạng neuron tích chập (CNN) được sử dụng phổ biển để nhận dạng các đối tượng trong ảnh hoặc video. Điểm đặc biệt của mô hình này là có khả năng phát hiện tất cả các đối tượng trong một hình ảnh chỉ qua một lần lan truyền của CNN.\n",
    "\n",
    "Các phương pháp truyền thống tách biệt bước đề xuất vùng và bước phân loại, YOLO xử lý đầu vào, vừa phân loại được các đối tượng, vừa dự đoán được vị trí của chúng trong một lần duy nhất.\n",
    "\n",
    "YOLO có nghĩa là \"You only look once\", nghĩa là chỉ cần \"nhìn\" một lần là thuật toán đã có thể phát hiện được vật thể, cho thấy độ nhanh của thuật toán gần như là real-time.\n",
    "\n",
    "Ứng dụng của YOLO cũng như nhiều thuật toán object detection khác, rất đa dạng: quản lý giao thông, đếm số sản phẩm trên băng chuyền nhà máy, đếm số vật nuôi trong chăn nuôi, phát hiện vật thể nguy hiểm (súng, dao,...), chấm công tự động,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c9885",
   "metadata": {},
   "source": [
    "## TẠO MÔI TRƯỜNG ẢO VÀ KERNEL CHẠY NOTEBOOK (LINUX)\n",
    "\n",
    "Dự án Python cần **môi trường ảo (virtual environment)** để tự cách ly, tránh xung đột phiên bản thư viện giữa các dự án. `venv` là môi trường ảo mà chúng ta sẽ sử dụng trong dự án này. Sau khi cài đặt `venv`, chúng ta di chuyển đường dẫn đến folder chứa dự án trong terminal và sử dụng lệnh sau để cài đặt môi trường ảo cho dự án:\n",
    "\n",
    "`python -m venv .venv`\n",
    "\n",
    "Trong đó, `.venv` là tên của folder chứa môi trường ảo của dự án, đồng thời nó cũng sẽ \"đóng băng\" phiên bản Python, pip và các thư viện sẽ được dùng trong dự án.\n",
    "\n",
    "Kích hoạt môi trường ảo:\n",
    "\n",
    "`source .venv/bin/activate`\n",
    "\n",
    "Lúc này, phiên bản Python và `pip` được dùng là của môi trường ảo, các thư viện cài bằng `pip install` cũng chỉ ảnh hưởng trong `.venv`. Cách nhận biết đang ở môi trường ảo là promt terminal thường đổi thành `(.venv) user_name@machine:~` (nếu đang sử dụng Linux). Khi đã kích hoạt môi trường ảo, đảm bảo phiên bản Python và `pip` đã \"đóng băng\" trong đó, sử dụng lệnh:\n",
    "\n",
    "`which python && which pip`\n",
    "\n",
    "Nếu output có dạng `.../<project_name>/.venv/...` thì môi trường ảo đã được kích hoạt thành công.\n",
    "\n",
    "Tiếp theo, tạo một kernel để chạy Jupyter Notebook. Cài đặt `ipykernel` để tạo kernel:\n",
    "\n",
    "`python -m pip install ipykernel`\n",
    "\n",
    "Sau khi cài đặt thành công, tiến hành tạo kernel để chạy file `.ipynb`:\n",
    "\n",
    "`python -m ipykernel install --prefix .venv --name yolovenv --display-name \"this_project\"`\n",
    "\n",
    "`--prefix .venv`: kernel mặc định không tự lưu vào `.venv`, thuộc tính này sẽ lưu kernel đã tạo vào `.venv`  \n",
    "`--name yolovenv`: tên folder chứa kernel, ở đây tên folder là `yolovenv`. Kernel sẽ được lưu tại `.venv/share/jupyter/kernels/yolovenv/`  \n",
    "`--display-name \"this_project`: kernel sẽ hiển thị dưới tên `this_project` trong VS Code.\n",
    "\n",
    "Khi đã tạo kernel, click vào biểu tượng kernel ở góc trên bên phải, chọn\n",
    "$$\n",
    "\\text{Select Another Kernel} \\rightarrow \\text{Jupyter Kernel...} \\rightarrow \\text{this\\_project}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f1757",
   "metadata": {},
   "source": [
    "## KHAI BÁO THƯ VIỆN VÀ CHUẨN BỊ DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513c7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c99e5",
   "metadata": {},
   "source": [
    "Data được tải về tại các nguồn sau: \\\n",
    "- https://www.kaggle.com/datasets/antoreepjana/animals-detection-images-dataset \\\n",
    "- https://www.kaggle.com/datasets/biancaferreira/african-wildlife \\\n",
    "- https://www.kaggle.com/datasets/wutheringwang/dog-face-detectionyolo-format \\\n",
    "- https://www.kaggle.com/datasets/samuelayman/cat-dataset\n",
    "- https://universe.roboflow.com/labo-yolo/age-and-gender-xlnfj/dataset/3 \\\n",
    "\n",
    "Data sau khi được tải về sẽ được xử lý (gán lại class ID; phân loại thành các folder train, valid, test;...), sau đó được gộp thành một folder dataset duy nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3253f",
   "metadata": {},
   "source": [
    "Sau khi hoàn tất xử lý dataset, chúng ta sẽ kiểm tra dataset có bị thiếu **nhãn dữ liệu** ứng với mỗi ảnh hay không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96bf0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset: dataset/completed_dataset\n",
      "\n",
      "       total_images  missing_labels  missing_labels (%)\n",
      "train       20451.0             0.0                 0.0\n",
      "valid        6078.0             0.0                 0.0\n",
      "test         4637.0             0.0                 0.0\n",
      "\n",
      "\n",
      "Total images: \t 31166\n",
      "Missing: \t 0\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(\"dataset/completed_dataset\")\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "SPLITS = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "\n",
    "def count_missing(split):\n",
    "    images_dir = BASE_DIR / \"images\" / split\n",
    "    labels_dir = BASE_DIR / \"labels\" / split\n",
    "\n",
    "    total_images = 0\n",
    "    missing = 0\n",
    "\n",
    "    for img in images_dir.iterdir():\n",
    "        if img.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "\n",
    "        total_images += 1\n",
    "        label_path = labels_dir / f\"{img.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            missing += 1\n",
    "\n",
    "    return total_images, missing\n",
    "\n",
    "\n",
    "print(f\"Checking dataset: {str(BASE_DIR)}\\n\")\n",
    "\n",
    "grand_total = 0\n",
    "grand_missing = 0\n",
    "total_images_arr = np.array([])\n",
    "missing_arr = np.array([])\n",
    "percent_arr = np.array([])\n",
    "\n",
    "for split in SPLITS:\n",
    "    total_images, missing = count_missing(split)\n",
    "    grand_total += total_images\n",
    "    grand_missing += missing\n",
    "    percent = (missing / total_images * 100) if total_images > 0 else 0\n",
    "\n",
    "    total_images_arr = np.append(total_images_arr, total_images)\n",
    "    missing_arr = np.append(missing_arr, missing)\n",
    "    percent_arr = np.append(percent_arr, percent)\n",
    "\n",
    "np_table = np.array([total_images_arr, missing_arr, percent_arr])\n",
    "table = pd.DataFrame(np_table).transpose()\n",
    "table.columns = [\"total_images\", \"missing_labels\", \"missing_labels (%)\"]\n",
    "table.index = [\"train\", \"valid\", \"test\"]\n",
    "print(table)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Total images: \\t {grand_total}\")\n",
    "print(f\"Missing: \\t {grand_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da97b8",
   "metadata": {},
   "source": [
    "Theo kết quả được in ra, dataset có tổng cộng 31166 hình ảnh và không có ảnh nào không có label. Như vậy, data đã đúng với format của YOLO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54685499",
   "metadata": {},
   "source": [
    "## KHAI BÁO, HUẤN LUYỆN VÀ LƯU MÔ HÌNH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873fb78b",
   "metadata": {},
   "source": [
    "Hàm train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25bea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, dataset_path, project_path, project_name):\n",
    "    model.train(\n",
    "        data=dataset_path,\n",
    "        epochs=epochs,\n",
    "        imgsz=448,\n",
    "        batch=8,\n",
    "        workers=4,\n",
    "        device=0,  # Sử dụng GPU\n",
    "        project=project_path,\n",
    "        name=project_name,\n",
    "\n",
    "        # # Augmentation\n",
    "        # mosaic=0.25,\n",
    "        # mixup=0.0,\n",
    "        # copy_paste=0.0,\n",
    "\n",
    "        # # Optimization\n",
    "        # lr0=0.005,\n",
    "        # optimizer=\"SGD\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc73cc",
   "metadata": {},
   "source": [
    "Sử dụng model YOLO11s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1227b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 448, 0)\n",
      "\n",
      "(30, 448, 1)\n",
      "\n",
      "(30, 512, 0)\n",
      "\n",
      "(30, 512, 1)\n",
      "\n",
      "(50, 448, 0)\n",
      "\n",
      "(50, 448, 1)\n",
      "\n",
      "(50, 512, 0)\n",
      "\n",
      "(50, 512, 1)\n",
      "\n",
      "(80, 448, 0)\n",
      "\n",
      "(80, 448, 1)\n",
      "\n",
      "(80, 512, 0)\n",
      "\n",
      "(80, 512, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL = \"yolo11s.pt\"\n",
    "\n",
    "epochs_list = [30, 50, 80]\n",
    "imgsz_list = [448, 512]\n",
    "with_optimization = [0, 1]\n",
    "\n",
    "# Huấn luyện model với 12 tham số khác nhau\n",
    "paramter = list(product(epochs_list, imgsz_list, with_optimization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4cb71",
   "metadata": {},
   "source": [
    "Huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e345bec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Huấn luyện mô hình với dataset\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_path.exists():\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel has been trained already. It is being loaded again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mMODEL_PATH\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m     model = YOLO(\u001b[38;5;28mstr\u001b[39m(model_path))\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'MODEL_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"dataset/completed_dataset/data.yaml\"\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    # Lưu model tại \"runs/yolo11s_custom/epochs{...}\" sau khi train\n",
    "    model_path = Path(f\"runs/yolo11s_custom/epochs_{epochs}/weights/best.pt\")\n",
    "    project_path = \"runs/yolo11s_custom\"\n",
    "    project_name = f\"epochs_{epochs}\"\n",
    "\n",
    "    # Huấn luyện mô hình với dataset\n",
    "    if model_path.exists():\n",
    "        print(f\"Model has been trained already. It is being loaded again: {model_path}\")\n",
    "        model = YOLO(str(model_path))\n",
    "    else:\n",
    "        print(\"Model hasn't been trained. Start training...\")\n",
    "\n",
    "        # Train model dựa trên model gốc là YOLO11s\n",
    "        model = YOLO(BASE_MODEL)\n",
    "        train_model(\n",
    "            model=model,\n",
    "            epochs=epochs,\n",
    "            dataset_path=DATASET_PATH,\n",
    "            project_path=project_path,\n",
    "            project_name=project_name\n",
    "        )\n",
    "\n",
    "        # Load lại best.pt sau khi train, nếu không tìm thấy thì in ra lỗi\n",
    "        assert model_path.exists(), \"Training finished but file best.pt not found\"\n",
    "        model = YOLO(str(model_path))\n",
    "\n",
    "        print(\"Training finished\")\n",
    "\n",
    "    # Kiểm tra và khoá model với model gốc là YOLO11s\n",
    "    # assert model.model.yaml['name'] == 'yolo11s'\n",
    "    # model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb95f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2eaa45e",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "this_project",
   "language": "python",
   "name": "yolovenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
